{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"code_3_missing_values.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"CV6Ca0tct9t6","colab_type":"code","colab":{}},"source":["###############################\n","#                             #\n","#        ENCODE FACTORS       #\n","#                             #\n","###############################\n","\n","# performs label encoding\n","from sklearn.preprocessing import LabelEncoder\n","def label_encoding(df_train, df_valid, df_test):\n","    \n","    factors = df_train.select_dtypes('object').columns\n","    \n","    lbl = LabelEncoder()\n","\n","    for f in factors:        \n","        lbl.fit(list(df_train[f].values) + list(df_valid[f].values) + list(df_test[f].values))\n","        df_train[f] = lbl.transform(list(df_train[f].values))\n","        df_valid[f] = lbl.transform(list(df_valid[f].values))\n","        df_test[f]  = lbl.transform(list(df_test[f].values))\n","\n","    return df_train, df_valid, df_test\n","\n","import numpy as np\n","def reduce_mem_usage(df, verbose = True):\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2    \n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)    \n","    end_mem = df.memory_usage().sum() / 1024**2\n","    if verbose: \n","        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n","    return df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7kiA-DotHK8","colab_type":"code","outputId":"f67cf3c9-62af-44a1-f99a-32de2011947d","executionInfo":{"status":"ok","timestamp":1579588458314,"user_tz":-60,"elapsed":27426,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# GOOGLE COLAB SETUP\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PoNai-lPtJZe","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('drive/My Drive/Colab Notebooks/WIDS/WIDS/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kraLQ_ACs1DU","colab_type":"code","colab":{}},"source":["\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.style.use('dark_background')\n","%matplotlib inline\n","\n","import os\n","import time\n","import datetime\n","import random\n","import multiprocessing\n","import pickle\n","\n","import scipy.stats\n","\n","import gc\n","gc.enable()\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n","from sklearn.preprocessing import RobustScaler, LabelEncoder\n","from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n","\n","import lightgbm as lgb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaAGEJRotC7j","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('drive/My Drive/Colab Notebooks/WIDS/WIDS/codes')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnKQLwT_s1Da","colab_type":"code","colab":{}},"source":["############ RANDOMNESS\n","\n","# seed function\n","def seed_everything(seed = 42):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    \n","# set seed\n","seed = 42\n","seed_everything(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTrTKS7gs1Db","colab_type":"text"},"source":["### IMPORT"]},{"cell_type":"code","metadata":{"id":"Btmfn4ars1Dc","colab_type":"code","outputId":"aabd6fc8-f783-4cfb-aeb0-7f9c54d9283e","executionInfo":{"status":"ok","timestamp":1579588476287,"user_tz":-60,"elapsed":6376,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["############ DATA IMPORT\n","\n","# id data\n","train = pd.read_csv('./raw/training_v2.csv')\n","test  = pd.read_csv('./raw/unlabeled.csv')\n","\n","\n","# check dimensions\n","print(train.shape)\n","print(train.shape)\n","\n","train = train[-train['hospital_death'].isnull()]"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(91713, 186)\n","(91713, 186)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R3CRPC3ms1Dj","colab_type":"code","colab":{}},"source":["y     = train['hospital_death']\n","train = train.drop('hospital_death', axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cRltychs1Dm","colab_type":"code","colab":{}},"source":["############ FEAUTERS\n","\n","# drop bad features\n","excluded_feats = ['encounter_id', 'patient_id', 'readmission_status', 'hospital_id', 'icu_id']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTqkeQQis1Do","colab_type":"code","colab":{}},"source":["train['hospital_id'] = train['hospital_id'].astype('object')\n","test['hospital_id']  = test['hospital_id'].astype('object')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"7c72987e-c85b-4b57-d6f0-b38291e3099f","executionInfo":{"status":"ok","timestamp":1579588507261,"user_tz":-60,"elapsed":1381,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"id":"bSBERTcoz8DL","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["features = [f for f in train.columns if f not in excluded_feats]\n","print(train[features].shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(91713, 180)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FlMLLM8Nz7Tq","colab":{}},"source":["############ PARAMETERS\n","\n","# cores\n","cores = -1\n","# cross-validation\n","num_folds = 10\n","shuffle   = True\n","\n","# number of trees\n","max_rounds = 10000\n","stopping   = 600\n","verbose    = 250\n","\n","# LGB parameters\n","lgb_params = {\n","    'boosting_type':     'gbdt',\n","    'objective':         'binary',\n","    'metric':            'auc',\n","    'bagging_fraction':  0.9,\n","    'feature_fraction':  0.9,\n","    'lambda_l1':         0.1,\n","    'lambda_l2':         0.1,\n","    'min_split_gain':    0,\n","    'min_child_weight':  0.1,\n","    'min_child_samples': 10,\n","    'silent':            True,\n","    'verbosity':         -1,\n","    'learning_rate':     0.01,\n","    'max_depth':         5,\n","    'num_leaves':        64,\n","    'scale_pos_weight':  1,\n","    'n_estimators':      max_rounds,\n","    'nthread' :          cores,\n","    'random_state':      seed,\n","    #\"device\" : \"gpu\"\n","}\n","\n","# data partitinoing\n","folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n","#folds = GroupKFold(n_splits = num_folds)\n","#folds = model_selection.TimeSeriesSplit(n_splits = 10)\n","\n","# SMOTE settings\n","#from imblearn.over_sampling import SMOTE\n","#sm = SMOTE(random_state = seed, n_jobs = cores, sampling_strategy = 0.05)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3bXNRyNyz6zq","colab":{}},"source":["\n","############ PLACEHOLDERS\n","\n","# placeholders\n","clfs = []\n","importances = pd.DataFrame()\n","\n","# predictions\n","preds_test   = np.zeros(test.shape[0])\n","preds_oof    = np.zeros(train.shape[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DI841VDx0jcl","colab_type":"code","colab":{}},"source":["train.fillna(train.median(), inplace=True)\n","test.fillna(train.median(), inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q44bOYsSs1Ds","colab_type":"code","outputId":"88fcc0ae-5633-446d-e751-235127d71939","executionInfo":{"status":"error","timestamp":1579549833157,"user_tz":-60,"elapsed":1040650,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["############ CROSS-VALIDATION LOOP\n","cv_start  = time.time()\n","for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n","\n","    # data partitioning\n","    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n","    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n","    test_x       = test[features]\n","    \n","    ## augment training data with SMOTE\n","    #trn_x[trn_x.columns]  = trn_x[trn_x.columns].apply(pd.to_numeric,   errors = 'coerce')\n","    #val_x[val_x.columns]  = val_x[val_x.columns].apply(pd.to_numeric,   errors = 'coerce')\n","    #test_x[val_x.columns] = test_x[test_x.columns].apply(pd.to_numeric, errors = 'coerce')\n","    #trn_x  = trn_x.replace([np.inf,  -np.inf], np.nan)\n","    #val_x  = val_x.replace([np.inf,  -np.inf], np.nan)\n","    #test_x = test_x.replace([np.inf, -np.inf], np.nan)\n","    #trn_x  = trn_x.fillna(trn_x.median())\n","    #val_x  = val_x.fillna(val_x.median())\n","    #test_x = test_x.fillna(test_x.median())\n","    #trn_x, trn_y = sm.fit_sample(trn_x, trn_y)\n","    #trn_x = pd.DataFrame(trn_x, columns = features)\n","    #trn_y = pd.Series(trn_y)\n","    \n","    # Aggregate data\n","    '''agg_features = list(trn_x.select_dtypes('number').columns)\n","    aggregated = list(trn_x.select_dtypes('object').columns)\n","    for variable in aggregated:\n","        print(f'preparing {variable}')\n","        agg_features.append(variable)\n","        features_ = trn_x[agg_features].groupby(variable).mean()\n","        features_.columns = [f'{variable}_{column}_mean' for column in features_.columns]\n","        trn_x  = trn_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        val_x  = val_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        test_x = test_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        agg_features.remove(variable)'''\n","        \n","    '''for variable in aggregated:\n","        print(f'preparing {variable}')\n","        agg_features.append(variable)\n","        features_ = trn_x[agg_features].groupby(variable).sum()\n","        features_.columns = [f'{variable}_{column}_sum' for column in features_.columns]\n","        trn_x  = trn_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        val_x  = val_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        test_x = test_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        agg_features.remove(variable)\n","    \n","    for variable in aggregated:\n","        print(f'preparing {variable}')\n","        agg_features.append(variable)\n","        features_ = trn_x[agg_features].groupby(variable).std()\n","        features_.columns = [f'{variable}_{column}_std' for column in features_.columns]\n","        trn_x  = trn_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        val_x  = val_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        test_x = test_x.merge(features_, left_on=variable, right_on=variable, how='left')\n","        agg_features.remove(variable)'''\n","        \n","        \n","    # Fill Na\n","    trn_x['weight']  = trn_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n","    val_x['weight']  = val_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n","    test_x['weight'] = test_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n","    \n","    trn_x['height']  = trn_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n","    val_x['height']  = val_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n","    test_x['height'] = test_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n","    \n","    trn_x['bmi']  = trn_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n","    val_x['bmi']  = val_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n","    test_x['bmi'] = test_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n","    \n","    for column in trn_x.select_dtypes('object').columns:\n","        trn_x[column] = trn_x[column].fillna('')\n","        val_x[column] = val_x[column].fillna('')\n","        test_x[column] = test_x[column].fillna('')\n","        \n","    # label encoding\n","    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test_x)\n","    \n","    \n","    ## remove outliers\n","    # num_vars = trn_x.select_dtypes(include='number')\n","    #num_vars = num_vars.columns\n","    #for num_var in num_vars:\n","    #    trn_x[num_var] = trn_x[num_var].replace([np.inf, -np.inf], np.nan)\n","    #    trn_x[num_var] = trn_x[num_var].fillna(trn_x[num_var].median())\n","    #out_idx = (np.abs(scipy.stats.zscore(trn_x[num_vars])) < 20).all(axis = 1) + (trn_y.values == 1)\n","    #trn_x = trn_x[out_idx]\n","    \n","    ## scale data\n","    #val_x  = val_x.replace([np.inf, -np.inf], np.nan)\n","    \n","    #scaler   = RobustScaler()\n","    #trn_x    = pd.DataFrame(scaler.fit_transform(trn_x))\n","    #val_x    = pd.DataFrame(scaler.transform(val_x))\n","    #test_x   = pd.DataFrame(scaler.transform(test_x))\n","       \n","    ## add noise to train to reduce overfitting\n","    trn_x += np.random.normal(0, 0.01, trn_x.shape)\n","    \n","    # print data dimensions\n","    print('Data shape:', trn_x.shape, val_x.shape)\n","    #print('Data shape:', trn_y.shape, val_y.shape)    \n","    # train lightGBM\n","    clf = lgb.LGBMClassifier(**lgb_params) \n","    clf = clf.fit(trn_x, trn_y, \n","                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n","                  eval_metric           = 'auc', \n","                  early_stopping_rounds = stopping,\n","                  verbose               = verbose)\n","    clfs.append(clf)\n","    \n","    # find the best iteration\n","    best_iter = clf.best_iteration_\n","\n","    # save predictions\n","    preds_oof[val_idx] = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n","    preds_test        += clf.predict_proba(test_x, num_iteration = best_iter)[:, 1] / folds.n_splits \n","\n","    # importance\n","    fold_importance_df               = pd.DataFrame()\n","    fold_importance_df['Feature']    = trn_x.columns\n","    fold_importance_df['Importance'] = clf.feature_importances_\n","    fold_importance_df['Fold']       = n_fold + 1\n","    importances                      = pd.concat([importances, fold_importance_df], axis = 0)\n","    \n","    # print performance\n","    print('--------------------------------')\n","    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n","    print('--------------------------------')\n","    print('')\n","        \n","    # clear memory\n","    del trn_x, trn_y, val_x, val_y\n","    gc.collect()\n","    \n","    \n","# print overall performance    \n","cv_perf = roc_auc_score(y, preds_oof)\n","print('--------------------------------')\n","print('- OOF AUC = %.6f' % cv_perf)\n","print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n","print('--------------------------------')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Data shape: (82541, 180) (9172, 180)\n","Training until validation scores don't improve for 600 rounds.\n","[250]\ttraining's auc: 0.909104\tvalid_1's auc: 0.888327\n","[500]\ttraining's auc: 0.925679\tvalid_1's auc: 0.896576\n","[750]\ttraining's auc: 0.935998\tvalid_1's auc: 0.898795\n","[1000]\ttraining's auc: 0.943977\tvalid_1's auc: 0.900015\n","[1250]\ttraining's auc: 0.950956\tvalid_1's auc: 0.900863\n","[1500]\ttraining's auc: 0.957085\tvalid_1's auc: 0.901945\n","[1750]\ttraining's auc: 0.962425\tvalid_1's auc: 0.902667\n","[2000]\ttraining's auc: 0.966805\tvalid_1's auc: 0.902897\n","[2250]\ttraining's auc: 0.970777\tvalid_1's auc: 0.903184\n","[2500]\ttraining's auc: 0.974105\tvalid_1's auc: 0.903301\n","[2750]\ttraining's auc: 0.977167\tvalid_1's auc: 0.903354\n","[3000]\ttraining's auc: 0.979875\tvalid_1's auc: 0.903262\n","[3250]\ttraining's auc: 0.982387\tvalid_1's auc: 0.903271\n","Early stopping, best iteration is:\n","[2820]\ttraining's auc: 0.977986\tvalid_1's auc: 0.903439\n","--------------------------------\n","FOLD 1: AUC = 0.903439\n","--------------------------------\n","\n","Data shape: (82541, 180) (9172, 180)\n","Training until validation scores don't improve for 600 rounds.\n","[250]\ttraining's auc: 0.908421\tvalid_1's auc: 0.89138\n","[500]\ttraining's auc: 0.923857\tvalid_1's auc: 0.900493\n","[750]\ttraining's auc: 0.934468\tvalid_1's auc: 0.90405\n","[1000]\ttraining's auc: 0.942279\tvalid_1's auc: 0.90603\n","[1250]\ttraining's auc: 0.948897\tvalid_1's auc: 0.907315\n","[1500]\ttraining's auc: 0.954857\tvalid_1's auc: 0.908059\n","[1750]\ttraining's auc: 0.959975\tvalid_1's auc: 0.90862\n","[2000]\ttraining's auc: 0.964352\tvalid_1's auc: 0.908765\n","[2250]\ttraining's auc: 0.968182\tvalid_1's auc: 0.908893\n","[2500]\ttraining's auc: 0.971653\tvalid_1's auc: 0.909007\n","[2750]\ttraining's auc: 0.97498\tvalid_1's auc: 0.9091\n","[3000]\ttraining's auc: 0.977812\tvalid_1's auc: 0.909127\n","[3250]\ttraining's auc: 0.980416\tvalid_1's auc: 0.909205\n","[3500]\ttraining's auc: 0.982815\tvalid_1's auc: 0.909214\n","[3750]\ttraining's auc: 0.985006\tvalid_1's auc: 0.909187\n","[4000]\ttraining's auc: 0.986818\tvalid_1's auc: 0.90903\n","Early stopping, best iteration is:\n","[3565]\ttraining's auc: 0.983463\tvalid_1's auc: 0.909308\n","--------------------------------\n","FOLD 2: AUC = 0.909308\n","--------------------------------\n","\n","Data shape: (82541, 180) (9172, 180)\n","Training until validation scores don't improve for 600 rounds.\n","[250]\ttraining's auc: 0.908735\tvalid_1's auc: 0.892194\n","[500]\ttraining's auc: 0.924523\tvalid_1's auc: 0.898829\n","[750]\ttraining's auc: 0.934877\tvalid_1's auc: 0.902332\n","[1000]\ttraining's auc: 0.94309\tvalid_1's auc: 0.904328\n","[1250]\ttraining's auc: 0.95048\tvalid_1's auc: 0.905481\n","[1500]\ttraining's auc: 0.956284\tvalid_1's auc: 0.906307\n","[1750]\ttraining's auc: 0.961394\tvalid_1's auc: 0.906811\n","[2000]\ttraining's auc: 0.965875\tvalid_1's auc: 0.907124\n","[2250]\ttraining's auc: 0.969858\tvalid_1's auc: 0.907253\n","[2500]\ttraining's auc: 0.973573\tvalid_1's auc: 0.90722\n","[2750]\ttraining's auc: 0.976752\tvalid_1's auc: 0.907365\n","[3000]\ttraining's auc: 0.979435\tvalid_1's auc: 0.907342\n","[3250]\ttraining's auc: 0.981847\tvalid_1's auc: 0.907207\n","Early stopping, best iteration is:\n","[2862]\ttraining's auc: 0.977965\tvalid_1's auc: 0.90747\n","--------------------------------\n","FOLD 3: AUC = 0.907470\n","--------------------------------\n","\n","Data shape: (82542, 180) (9171, 180)\n","Training until validation scores don't improve for 600 rounds.\n","[250]\ttraining's auc: 0.909553\tvalid_1's auc: 0.882451\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-137-0f6bdafac4bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m                   \u001b[0meval_metric\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                   \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                   verbose               = verbose)\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mclfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"hWHIEpSds1Du","colab_type":"text"},"source":["### EVALUATION"]},{"cell_type":"code","metadata":{"id":"lZNWGMc6s1Dv","colab_type":"code","colab":{}},"source":["############ RECHECK PERFORMANCE  \n","\n","# check performance\n","print(np.round(roc_auc_score(y, preds_oof), 5))\n","\n","\n","############ TRACK RESULTS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F2w6VAeHs1Dw","colab_type":"code","colab":{}},"source":["############ VARIABLE IMPORTANCE\n","\n","# load importance    \n","top_feats = 300\n","cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n","importance = importances.loc[importances.Feature.isin(cols)]\n","    \n","# plot variable importance\n","plt.figure(figsize = (10, 150))\n","sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n","plt.tight_layout()\n","plt.savefig('../var_importance.pdf')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UbGUmx1s1Dy","colab_type":"text"},"source":["SUBMISSION"]},{"cell_type":"code","metadata":{"id":"Ut1uW95ds1Dy","colab_type":"code","colab":{}},"source":["# file name\n","model = 'lgb_v21'\n","perf  = str(round(cv_perf, 6))[2:7]\n","name  = model + '_' + perf\n","name"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ox2RkuQks1D0","colab_type":"code","colab":{}},"source":["# export OOF preds\n","oof = pd.DataFrame({'encounter_id': train['encounter_id'], 'hospital_death': preds_oof})\n","oof.to_csv('./oof_preds/' + str(name) + '.csv', index = False)\n","oof.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JprRz1pPs1D1","colab_type":"code","colab":{}},"source":["\n","# export submission\n","sub = pd.DataFrame({'encounter_id': test['encounter_id'], 'hospital_death': preds_test})\n","sub.to_csv('./submissions/' + str(name) + '.csv', index = False)\n","sub.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iL6guDaxxgQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}