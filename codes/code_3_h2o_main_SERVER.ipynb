{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJLXVEldsT0N"
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CV6Ca0tct9t6"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#                             #\n",
    "#        ENCODE FACTORS       #\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "# performs label encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "def label_encoding(df_train, df_valid, df_test):\n",
    "    \n",
    "    factors = df_train.select_dtypes('object').columns\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    for f in factors:        \n",
    "        lbl.fit(list(df_train[f].values) + list(df_valid[f].values) + list(df_test[f].values))\n",
    "        df_train[f] = lbl.transform(list(df_train[f].values))\n",
    "        df_valid[f] = lbl.transform(list(df_valid[f].values))\n",
    "        df_test[f]  = lbl.transform(list(df_test[f].values))\n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "from sklearn import base\n",
    "class KFoldTargetEncoderTrain(base.BaseEstimator,\n",
    "                               base.TransformerMixin):\n",
    "    def __init__(self,colnames,targetName,\n",
    "                  n_fold=5, verbosity=True,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = False, random_state=2019)\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] =  X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "        if self.verbosity:\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X\n",
    "\n",
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        \n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        mean =  self.train[[self.colNames,\n",
    "                self.encodedName]].groupby(\n",
    "                                self.colNames).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kraLQ_ACs1DU"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnKQLwT_s1Da"
   },
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTrTKS7gs1Db"
   },
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10509,
     "status": "ok",
     "timestamp": 1579724379901,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "Btmfn4ars1Dc",
    "outputId": "39471385-9461-4a81-f04f-e1d7500c0b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91713, 186)\n",
      "(39308, 186)\n"
     ]
    }
   ],
   "source": [
    "############ DATA IMPORT\n",
    "\n",
    "# id data\n",
    "train = pd.read_csv('../raw/training.csv')\n",
    "test  = pd.read_csv('../raw/unlabeled.csv')\n",
    "\n",
    "train = train[-train['hospital_death'].isnull()]\n",
    "\n",
    "\n",
    "# check dimensions\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1LtthC77b22"
   },
   "outputs": [],
   "source": [
    "train['NAs'] = train.isnull().sum(axis=1)\n",
    "test['NAs']  = test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0iX8GebXLAF"
   },
   "outputs": [],
   "source": [
    "train['hospital_id'] = train['hospital_id'].astype('object')\n",
    "test['hospital_id']  = test['hospital_id'].astype('object')\n",
    "\n",
    "train['icu_id'] = train['icu_id'].astype('object')\n",
    "test['icu_id']  = test['icu_id'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3CRPC3ms1Dj"
   },
   "outputs": [],
   "source": [
    "y     = train['hospital_death']\n",
    "train = train.drop('hospital_death', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cRltychs1Dm"
   },
   "outputs": [],
   "source": [
    "############ FEAUTERS\n",
    "\n",
    "# drop bad features\n",
    "excluded_feats = ['encounter_id', 'patient_id', 'readmission_status', 'hospital_id', 'icu_id']\n",
    "excluded_feats.extend(list(train.select_dtypes('object').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C42jQtu6_3gn"
   },
   "outputs": [],
   "source": [
    "train['apache_prob_prod'] = train['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']\n",
    "test['apache_prob_prod'] = test['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19732,
     "status": "ok",
     "timestamp": 1579724393290,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "uhKO586aSSbs",
    "outputId": "efd54b0b-39f2-4c1f-e5dd-4a5c3772448b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91713, 174)\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "#features = ['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob']\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dY4hYR2rs1Dp"
   },
   "outputs": [],
   "source": [
    "############ PARAMETERS\n",
    "\n",
    "# cores\n",
    "cores = -1\n",
    "# cross-validation\n",
    "num_folds = 10\n",
    "shuffle   = True\n",
    "\n",
    "# number of trees\n",
    "max_rounds = 10000\n",
    "stopping   = 200\n",
    "verbose    = 250\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metric':            'auc',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0.1,\n",
    "    'min_child_weight':  0,\n",
    "    'min_child_samples': 10,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.01,\n",
    "    'max_depth':         5,\n",
    "    'num_leaves':        64,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "    #\"device\" : \"gpu\"\n",
    "}\n",
    "\n",
    "# data partitinoing\n",
    "folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "#folds = GroupKFold(n_splits = num_folds)\n",
    "#folds = model_selection.TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "# SMOTE settings\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state = seed, n_jobs = cores, sampling_strategy = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2u9ywow1s1Dr"
   },
   "outputs": [],
   "source": [
    "\n",
    "############ PLACEHOLDERS\n",
    "\n",
    "# placeholders\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "# predictions\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43741,
     "status": "ok",
     "timestamp": 1579724419494,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "Eh2F5rOasPvR",
    "outputId": "d73294dc-6116-4c90-b1fd-509f8927278d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_242\"; OpenJDK Runtime Environment (build 1.8.0_242-b08); OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)\n",
      "  Starting server from /home/RDC/zinovyee.hub/.conda/envs/wids/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpeyroby50\n",
      "  JVM stdout: /tmp/tmpeyroby50/h2o_zinovyee_hub_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpeyroby50/h2o_zinovyee_hub_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>17 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_zinovyee_hub_71hfe8</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>26.67 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.10 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Europe/Berlin\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.3\n",
       "H2O cluster version age:    17 days\n",
       "H2O cluster name:           H2O_from_python_zinovyee_hub_71hfe8\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    26.67 Gb\n",
       "H2O cluster total cores:    32\n",
       "H2O cluster allowed cores:  32\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.6.10 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116733,
     "status": "ok",
     "timestamp": 1579711575456,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "q44bOYsSs1Ds",
    "outputId": "9abe752c-7657-4a5e-bc49-db97d0ffbb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Data shape: (82541, 175) (9172, 175)\n",
      "AutoML progress: |██"
     ]
    }
   ],
   "source": [
    "############ CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
    "\n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    test_x       = test[features]\n",
    "        \n",
    "    # Fill Na\n",
    "    #trn_x['weight']  = trn_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n",
    "    #val_x['weight']  = val_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n",
    "    #test_x['weight'] = test_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n",
    "    \n",
    "    #trn_x['height']  = trn_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n",
    "    #val_x['height']  = val_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n",
    "    #test_x['height'] = test_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n",
    "    \n",
    "    #trn_x['bmi']  = trn_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n",
    "    #val_x['bmi']  = val_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n",
    "    #test_x['bmi'] = test_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n",
    "    \n",
    "    for column in trn_x.select_dtypes('object').columns:\n",
    "        trn_x[column] = trn_x[column].fillna('')\n",
    "        val_x[column] = val_x[column].fillna('')\n",
    "        test_x[column] = test_x[column].fillna('')\n",
    "        \n",
    "    # label encoding\n",
    "    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test_x)\n",
    "       \n",
    "    ## add noise to train to reduce overfitting\n",
    "    trn_x += np.random.normal(0, 0.01, trn_x.shape)\n",
    "    \n",
    "    x_ = list(trn_x.columns)\n",
    "    y_ = 'hospital_death'\n",
    "\n",
    "    trn_x = h2o.H2OFrame(pd.concat([trn_y, trn_x], axis=1))\n",
    "    val_x = h2o.H2OFrame(pd.concat([val_y, val_x], axis=1))\n",
    "    if n_fold == 0:\n",
    "      test_x = h2o.H2OFrame(test_x)\n",
    "\n",
    "    trn_x['hospital_death'] = trn_x['hospital_death'].asfactor()\n",
    "    val_x['hospital_death'] = val_x['hospital_death'].asfactor()\n",
    "\n",
    "    # print data dimensions\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "    #print('Data shape:', trn_y.shape, val_y.shape)    \n",
    "    # train lightGBM\n",
    "    aml = H2OAutoML(max_models = 1, seed = seed, stopping_metric = 'auc')\n",
    "    aml.train(x = x_, y = y_, training_frame = trn_x)\n",
    "    \n",
    "\n",
    "    # save predictions\n",
    "    preds_oof[val_idx] = aml.leader.predict(val_x)\n",
    "    preds_test        += aml.leader.predict(test_x) / folds.n_splits \n",
    "\n",
    "    \n",
    "    # print performance\n",
    "    print('--------------------------------')\n",
    "    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('--------------------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWHIEpSds1Du"
   },
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZNWGMc6s1Dv"
   },
   "outputs": [],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))\n",
    "\n",
    "\n",
    "############ TRACK RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2w6VAeHs1Dw"
   },
   "outputs": [],
   "source": [
    "############ VARIABLE IMPORTANCE\n",
    "\n",
    "# load importance    \n",
    "top_feats = 300\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.Feature.isin(cols)]\n",
    "    \n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 150))\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n",
    "plt.tight_layout()\n",
    "plt.savefig('./var_importance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UbGUmx1s1Dy"
   },
   "source": [
    "SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut1uW95ds1Dy"
   },
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'h2o_v1'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox2RkuQks1D0"
   },
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "oof = pd.DataFrame({'encounter_id': train['encounter_id'], 'hospital_death': preds_oof})\n",
    "oof.to_csv('./oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JprRz1pPs1D1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# export submission\n",
    "sub = pd.DataFrame({'encounter_id': test['encounter_id'], 'hospital_death': preds_test})\n",
    "sub.to_csv('./submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_3_h2o_main_COLAB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "wids",
   "language": "python",
   "name": "wids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
