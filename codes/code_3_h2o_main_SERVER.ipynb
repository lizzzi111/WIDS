{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJLXVEldsT0N"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h2o'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0663a94f5a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH2OAutoML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h2o'"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CV6Ca0tct9t6"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#                             #\n",
    "#        ENCODE FACTORS       #\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "# performs label encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "def label_encoding(df_train, df_valid, df_test):\n",
    "    \n",
    "    factors = df_train.select_dtypes('object').columns\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    for f in factors:        \n",
    "        lbl.fit(list(df_train[f].values) + list(df_valid[f].values) + list(df_test[f].values))\n",
    "        df_train[f] = lbl.transform(list(df_train[f].values))\n",
    "        df_valid[f] = lbl.transform(list(df_valid[f].values))\n",
    "        df_test[f]  = lbl.transform(list(df_test[f].values))\n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "from sklearn import base\n",
    "class KFoldTargetEncoderTrain(base.BaseEstimator,\n",
    "                               base.TransformerMixin):\n",
    "    def __init__(self,colnames,targetName,\n",
    "                  n_fold=5, verbosity=True,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = False, random_state=2019)\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] =  X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "        if self.verbosity:\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X\n",
    "\n",
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        \n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        mean =  self.train[[self.colNames,\n",
    "                self.encodedName]].groupby(\n",
    "                                self.colNames).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kraLQ_ACs1DU"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnKQLwT_s1Da"
   },
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTrTKS7gs1Db"
   },
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10509,
     "status": "ok",
     "timestamp": 1579724379901,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "Btmfn4ars1Dc",
    "outputId": "39471385-9461-4a81-f04f-e1d7500c0b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91713, 186)\n",
      "(39308, 186)\n"
     ]
    }
   ],
   "source": [
    "############ DATA IMPORT\n",
    "\n",
    "# id data\n",
    "train = pd.read_csv('../raw/training.csv')\n",
    "test  = pd.read_csv('../raw/unlabeled.csv')\n",
    "\n",
    "train = train[-train['hospital_death'].isnull()]\n",
    "\n",
    "\n",
    "# check dimensions\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1LtthC77b22"
   },
   "outputs": [],
   "source": [
    "train['NAs'] = train.isnull().sum(axis=1)\n",
    "test['NAs']  = test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0iX8GebXLAF"
   },
   "outputs": [],
   "source": [
    "train['hospital_id'] = train['hospital_id'].astype('object')\n",
    "test['hospital_id']  = test['hospital_id'].astype('object')\n",
    "\n",
    "train['icu_id'] = train['icu_id'].astype('object')\n",
    "test['icu_id']  = test['icu_id'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21332,
     "status": "ok",
     "timestamp": 1579724392319,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "70hZBqHN6Hv5",
    "outputId": "24a07064-524a-43cb-f1fc-a3b4cefaa2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, hospital_id_Kfold_Target_Enc and, hospital_death is 0.06181569806601605.\n",
      "Correlation between the new feature, ethnicity_Kfold_Target_Enc and, hospital_death is -0.02177803191599158.\n",
      "Correlation between the new feature, gender_Kfold_Target_Enc and, hospital_death is -0.024544747506578066.\n",
      "Correlation between the new feature, hospital_admit_source_Kfold_Target_Enc and, hospital_death is 0.0960169239814269.\n",
      "Correlation between the new feature, icu_admit_source_Kfold_Target_Enc and, hospital_death is 0.10751265094405522.\n",
      "Correlation between the new feature, icu_id_Kfold_Target_Enc and, hospital_death is 0.0733113785264604.\n",
      "Correlation between the new feature, icu_stay_type_Kfold_Target_Enc and, hospital_death is -9.430062769425183e-05.\n",
      "Correlation between the new feature, icu_type_Kfold_Target_Enc and, hospital_death is 0.038222640788087354.\n",
      "Correlation between the new feature, apache_3j_bodysystem_Kfold_Target_Enc and, hospital_death is 0.1229191431318211.\n",
      "Correlation between the new feature, apache_2_bodysystem_Kfold_Target_Enc and, hospital_death is 0.10683882439078841.\n"
     ]
    }
   ],
   "source": [
    "for feature in train.select_dtypes('object').columns:    \n",
    "    targetc = KFoldTargetEncoderTrain(feature,'hospital_death',n_fold=10)\n",
    "    train = targetc.fit_transform(train)\n",
    "\n",
    "    test_targetc = KFoldTargetEncoderTest(train,\n",
    "                                          feature,\n",
    "                                          f'{feature}_Kfold_Target_Enc')\n",
    "    test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3CRPC3ms1Dj"
   },
   "outputs": [],
   "source": [
    "y     = train['hospital_death']\n",
    "train = train.drop('hospital_death', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cRltychs1Dm"
   },
   "outputs": [],
   "source": [
    "############ FEAUTERS\n",
    "\n",
    "# drop bad features\n",
    "excluded_feats = ['encounter_id', 'patient_id', 'readmission_status', 'hospital_id', 'icu_id']\n",
    "excluded_feats.extend(list(train.select_dtypes('object').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C42jQtu6_3gn"
   },
   "outputs": [],
   "source": [
    "train['apache_prob_prod'] = train['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']\n",
    "test['apache_prob_prod'] = test['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19732,
     "status": "ok",
     "timestamp": 1579724393290,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "uhKO586aSSbs",
    "outputId": "efd54b0b-39f2-4c1f-e5dd-4a5c3772448b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91713, 184)\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "#features = ['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob']\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dY4hYR2rs1Dp"
   },
   "outputs": [],
   "source": [
    "############ PARAMETERS\n",
    "\n",
    "# cores\n",
    "cores = -1\n",
    "# cross-validation\n",
    "num_folds = 10\n",
    "shuffle   = True\n",
    "\n",
    "# number of trees\n",
    "max_rounds = 10000\n",
    "stopping   = 200\n",
    "verbose    = 250\n",
    "\n",
    "# LGB parameters\n",
    "lgb_params = {\n",
    "    'boosting_type':     'gbdt',\n",
    "    'objective':         'binary',\n",
    "    'metric':            'auc',\n",
    "    'bagging_fraction':  0.9,\n",
    "    'feature_fraction':  0.9,\n",
    "    'lambda_l1':         0.1,\n",
    "    'lambda_l2':         0.1,\n",
    "    'min_split_gain':    0.1,\n",
    "    'min_child_weight':  0,\n",
    "    'min_child_samples': 10,\n",
    "    'silent':            True,\n",
    "    'verbosity':         -1,\n",
    "    'learning_rate':     0.01,\n",
    "    'max_depth':         5,\n",
    "    'num_leaves':        64,\n",
    "    'scale_pos_weight':  1,\n",
    "    'n_estimators':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'random_state':      seed,\n",
    "    #\"device\" : \"gpu\"\n",
    "}\n",
    "\n",
    "# data partitinoing\n",
    "folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "#folds = GroupKFold(n_splits = num_folds)\n",
    "#folds = model_selection.TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "# SMOTE settings\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state = seed, n_jobs = cores, sampling_strategy = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2u9ywow1s1Dr"
   },
   "outputs": [],
   "source": [
    "\n",
    "############ PLACEHOLDERS\n",
    "\n",
    "# placeholders\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "# predictions\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43741,
     "status": "ok",
     "timestamp": 1579724419494,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "Eh2F5rOasPvR",
    "outputId": "d73294dc-6116-4c90-b1fd-509f8927278d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n"
     ]
    },
    {
     "ename": "H2OStartupError",
     "evalue": "Cannot find Java. Please install the latest JRE from\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(url, ip, port, name, https, cacert, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, log_dir, log_level, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, extra_classpath, jvm_custom_args, bind_to_localhost, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m                                      _msgs=(\"Checking whether there is an H2O instance running at {url} \",\n\u001b[1;32m--> 302\u001b[1;33m                                             \"connected.\", \"not found.\"))\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mH2OConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\backend\\connection.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(server, url, ip, port, name, https, auth, verify_ssl_certificates, cacert, proxy, cookies, verbose, _msgs)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_msgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m             \u001b[1;31m# If a server is unable to respond within 1s, it should be considered a bug. However we disable this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\backend\\connection.py\u001b[0m in \u001b[0;36m_test_connection\u001b[1;34m(self, max_retries, messages)\u001b[0m\n\u001b[0;32m    683\u001b[0m             raise H2OConnectionError(\"Could not establish link to the H2O cloud %s after %d retries\\n%s\"\n\u001b[1;32m--> 684\u001b[1;33m                                      % (self._base_url, max_retries, \"\\n\".join(errors)))\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OConnectionError\u001b[0m: Could not establish link to the H2O cloud http://localhost:54321 after 5 retries\n[31:25.49] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000000458047F908>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[31:27.69] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000000458047FA90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[31:29.92] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000000458048F278>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[31:32.21] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000000458048F940>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n[31:34.50] H2OConnectionError: Unexpected HTTP error: HTTPConnectionPool(host='localhost', port=54321): Max retries exceeded with url: /3/Cloud (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000000458109B160>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mH2OStartupError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-95453bf1556d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(url, ip, port, name, https, cacert, insecure, username, password, cookies, proxy, start_h2o, nthreads, ice_root, log_dir, log_level, enable_assertions, max_mem_size, min_mem_size, strict_version_check, ignore_config, extra_classpath, jvm_custom_args, bind_to_localhost, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m                                   \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                                   \u001b[0mextra_classpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextra_classpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvm_custom_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjvm_custom_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                                   bind_to_localhost=bind_to_localhost)\n\u001b[0m\u001b[0;32m    315\u001b[0m         h2oconn = H2OConnection.open(server=hs, https=https, verify_ssl_certificates=verify_ssl_certificates,\n\u001b[0;32m    316\u001b[0m                                      cacert=cacert, auth=auth, proxy=proxy,cookies=cookies, verbose=True)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\backend\\server.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(jar_path, nthreads, enable_assertions, max_mem_size, min_mem_size, ice_root, log_dir, log_level, port, name, extra_classpath, verbose, jvm_custom_args, bind_to_localhost)\u001b[0m\n\u001b[0;32m    138\u001b[0m         hs._launch_server(port=port, baseport=baseport, nthreads=int(nthreads), ea=enable_assertions,\n\u001b[0;32m    139\u001b[0m                           \u001b[0mmmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_mem_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_mem_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvm_custom_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjvm_custom_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                           bind_to_localhost=bind_to_localhost, log_dir=log_dir, log_level=log_level)\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  Server is running at %s://%s:%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0matexit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\backend\\server.py\u001b[0m in \u001b[0;36m_launch_server\u001b[1;34m(self, port, baseport, mmax, mmin, ea, nthreads, jvm_custom_args, bind_to_localhost, log_dir, log_level)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;31m# Find Java and check version. (Note that subprocess.check_output returns the output as a bytes object)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0mjava\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\deep\\lib\\site-packages\\h2o\\backend\\server.py\u001b[0m in \u001b[0;36m_find_java\u001b[1;34m()\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;31m# not found...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         raise H2OStartupError(\"Cannot find Java. Please install the latest JRE from\\n\"\n\u001b[0m\u001b[0;32m    436\u001b[0m                               \"http://www.oracle.com/technetwork/java/javase/downloads/index.html\")\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OStartupError\u001b[0m: Cannot find Java. Please install the latest JRE from\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html"
     ]
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1116733,
     "status": "ok",
     "timestamp": 1579711575456,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "q44bOYsSs1Ds",
    "outputId": "9abe752c-7657-4a5e-bc49-db97d0ffbb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Data shape: (82541, 185) (9172, 185)\n",
      "AutoML progress: |██"
     ]
    }
   ],
   "source": [
    "############ CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
    "\n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    test_x       = test[features]\n",
    "        \n",
    "    # Fill Na\n",
    "    #trn_x['weight']  = trn_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n",
    "    #val_x['weight']  = val_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n",
    "    #test_x['weight'] = test_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n",
    "    \n",
    "    #trn_x['height']  = trn_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n",
    "    #val_x['height']  = val_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n",
    "    #test_x['height'] = test_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n",
    "    \n",
    "    #trn_x['bmi']  = trn_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n",
    "    #val_x['bmi']  = val_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n",
    "    #test_x['bmi'] = test_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n",
    "    \n",
    "    for column in trn_x.select_dtypes('object').columns:\n",
    "        trn_x[column] = trn_x[column].fillna('')\n",
    "        val_x[column] = val_x[column].fillna('')\n",
    "        test_x[column] = test_x[column].fillna('')\n",
    "        \n",
    "    # label encoding\n",
    "    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test_x)\n",
    "       \n",
    "    ## add noise to train to reduce overfitting\n",
    "    trn_x += np.random.normal(0, 0.01, trn_x.shape)\n",
    "    \n",
    "    x_ = list(trn_x.columns)\n",
    "    y_ = 'hospital_death'\n",
    "\n",
    "    trn_x = h2o.H2OFrame(pd.concat([trn_y, trn_x], axis=1))\n",
    "    val_x = h2o.H2OFrame(pd.concat([val_y, val_x], axis=1))\n",
    "    if n_fold == 0:\n",
    "      test_x = h2o.H2OFrame(test_x)\n",
    "\n",
    "    trn_x['hospital_death'] = trn_x['hospital_death'].asfactor()\n",
    "    val_x['hospital_death'] = val_x['hospital_death'].asfactor()\n",
    "\n",
    "    # print data dimensions\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "    #print('Data shape:', trn_y.shape, val_y.shape)    \n",
    "    # train lightGBM\n",
    "    aml = H2OAutoML(max_models = 1, seed = seed, stopping_metric = 'auc')\n",
    "    aml.train(x = x_, y = y_, training_frame = trn_x)\n",
    "    \n",
    "\n",
    "    # save predictions\n",
    "    preds_oof[val_idx] = aml.leader.predict(val_x)\n",
    "    preds_test        += aml.leader.predict(test_x) / folds.n_splits \n",
    "\n",
    "    \n",
    "    # print performance\n",
    "    print('--------------------------------')\n",
    "    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('--------------------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWHIEpSds1Du"
   },
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZNWGMc6s1Dv"
   },
   "outputs": [],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))\n",
    "\n",
    "\n",
    "############ TRACK RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2w6VAeHs1Dw"
   },
   "outputs": [],
   "source": [
    "############ VARIABLE IMPORTANCE\n",
    "\n",
    "# load importance    \n",
    "top_feats = 300\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.Feature.isin(cols)]\n",
    "    \n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 150))\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n",
    "plt.tight_layout()\n",
    "plt.savefig('./var_importance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UbGUmx1s1Dy"
   },
   "source": [
    "SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ut1uW95ds1Dy"
   },
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'h2o_v1'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ox2RkuQks1D0"
   },
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "oof = pd.DataFrame({'encounter_id': train['encounter_id'], 'hospital_death': preds_oof})\n",
    "oof.to_csv('./oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JprRz1pPs1D1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# export submission\n",
    "sub = pd.DataFrame({'encounter_id': test['encounter_id'], 'hospital_death': preds_test})\n",
    "sub.to_csv('./submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_3_h2o_main_COLAB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
