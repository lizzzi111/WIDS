{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CV6Ca0tct9t6"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "#                             #\n",
    "#        ENCODE FACTORS       #\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "# performs label encoding\n",
    "def reduce_mem_usage(df, verbose = True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "def label_encoding(df_train, df_valid, df_test):\n",
    "    \n",
    "    factors = df_train.select_dtypes('object').columns\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    for f in factors:        \n",
    "        lbl.fit(list(df_train[f].values) + list(df_valid[f].values) + list(df_test[f].values))\n",
    "        df_train[f] = lbl.transform(list(df_train[f].values))\n",
    "        df_valid[f] = lbl.transform(list(df_valid[f].values))\n",
    "        df_test[f]  = lbl.transform(list(df_test[f].values))\n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "from sklearn import base\n",
    "class KFoldTargetEncoderTrain(base.BaseEstimator,\n",
    "                               base.TransformerMixin):\n",
    "    def __init__(self,colnames,targetName,\n",
    "                  n_fold=5, verbosity=True,\n",
    "                  discardOriginal_col=False):\n",
    "        self.colnames = colnames\n",
    "        self.targetName = targetName\n",
    "        self.n_fold = n_fold\n",
    "        self.verbosity = verbosity\n",
    "        self.discardOriginal_col = discardOriginal_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        assert(type(self.targetName) == str)\n",
    "        assert(type(self.colnames) == str)\n",
    "        assert(self.colnames in X.columns)\n",
    "        assert(self.targetName in X.columns)\n",
    "        mean_of_target = X[self.targetName].mean()\n",
    "        kf = KFold(n_splits = self.n_fold,\n",
    "                   shuffle = False, random_state=2019)\n",
    "        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n",
    "        X[col_mean_name] = np.nan\n",
    "        for tr_ind, val_ind in kf.split(X):\n",
    "            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n",
    "            X.loc[X.index[val_ind], col_mean_name] =  X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n",
    "            X[col_mean_name].fillna(mean_of_target, inplace = True)\n",
    "        if self.verbosity:\n",
    "            encoded_feature = X[col_mean_name].values\n",
    "            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n",
    "        if self.discardOriginal_col:\n",
    "            X = X.drop(self.targetName, axis=1)\n",
    "        return X\n",
    "\n",
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self,train,colNames,encodedName):\n",
    "        \n",
    "        self.train = train\n",
    "        self.colNames = colNames\n",
    "        self.encodedName = encodedName\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        mean =  self.train[[self.colNames,\n",
    "                self.encodedName]].groupby(\n",
    "                                self.colNames).mean().reset_index() \n",
    "        \n",
    "        dd = {}\n",
    "        for index, row in mean.iterrows():\n",
    "            dd[row[self.colNames]] = row[self.encodedName]\n",
    "        X[self.encodedName] = X[self.colNames]\n",
    "        X = X.replace({self.encodedName: dd})\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kraLQ_ACs1DU"
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.impute import SimpleImputer\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnKQLwT_s1Da"
   },
   "outputs": [],
   "source": [
    "############ RANDOMNESS\n",
    "\n",
    "# seed function\n",
    "def seed_everything(seed = 42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# set seed\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTrTKS7gs1Db"
   },
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3686,
     "status": "ok",
     "timestamp": 1579793991092,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "Btmfn4ars1Dc",
    "outputId": "d25b01c0-b400-4a96-82d4-eb858eee5c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110369, 186)\n",
      "(39308, 186)\n"
     ]
    }
   ],
   "source": [
    "############ DATA IMPORT\n",
    "\n",
    "# id data\n",
    "train = pd.read_csv('../raw/training.csv')\n",
    "test  = pd.read_csv('../raw/unlabeled.csv')\n",
    "\n",
    "\n",
    "# check dimensions\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train = train[-train['hospital_death'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 37.78 Mb (71.1% reduction)\n",
      "Mem. usage decreased to 16.01 Mb (71.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1LtthC77b22"
   },
   "outputs": [],
   "source": [
    "train['NAs'] = train.isnull().sum(axis=1)\n",
    "test['NAs']  = test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9446,
     "status": "ok",
     "timestamp": 1579793999265,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "70hZBqHN6Hv5",
    "outputId": "6e670d1c-0c25-447c-8209-d148da9a15bf"
   },
   "source": [
    "for feature in train.select_dtypes('object').columns:    \n",
    "    targetc = KFoldTargetEncoderTrain(feature,'hospital_death',n_fold=10)\n",
    "    train = targetc.fit_transform(train)\n",
    "\n",
    "    test_targetc = KFoldTargetEncoderTest(train,\n",
    "                                          feature,\n",
    "                                          f'{feature}_Kfold_Target_Enc')\n",
    "    test = test_targetc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3CRPC3ms1Dj"
   },
   "outputs": [],
   "source": [
    "y     = train['hospital_death']\n",
    "train = train.drop('hospital_death', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['apache_4a_hospital_death_prob'][train['apache_4a_hospital_death_prob']==-1] = np.nan\n",
    "test['apache_4a_hospital_death_prob'][test['apache_4a_hospital_death_prob']==-1] = np.nan\n",
    "\n",
    "train['apache_4a_icu_death_prob'][train['apache_4a_icu_death_prob']==-1] = np.nan\n",
    "test['apache_4a_icu_death_prob'][test['apache_4a_icu_death_prob']==-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['pre_icu_los_days']<0]['pre_icu_los_days'] = 0\n",
    "test[test['pre_icu_los_days']<0]['pre_icu_los_days'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C42jQtu6_3gn"
   },
   "outputs": [],
   "source": [
    "train['apache_prob_prod'] = train['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']\n",
    "test['apache_prob_prod'] = test['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJkR9Fc3b5Nb"
   },
   "outputs": [],
   "source": [
    "nulls = pd.DataFrame(train.isnull().sum(axis=0))\n",
    "excluded_feats = ['encounter_id', 'patient_id', 'readmission_status', 'hospital_id', 'icu_id', 'icu_type']\n",
    "excluded_feats.extend(list(nulls[nulls[0]>70000].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hospital_id'] = train['hospital_id'].astype('object')\n",
    "test['hospital_id']  = test['hospital_id'].astype('object')\n",
    "\n",
    "train['icu_id'] = train['icu_id'].astype('object')\n",
    "test['icu_id']  = test['icu_id'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_factor'] = 0\n",
    "train.loc[train['age']<10, 'age_factor'] = 'under_10'\n",
    "train.loc[((train['age']>10) & (train['age']<20)), 'age_factor'] = 'b_10_20'\n",
    "train.loc[((train['age']>20) & (train['age']<35)), 'age_factor'] = 'b_20_35'\n",
    "train.loc[((train['age']>35) & (train['age']<50)), 'age_factor'] = 'b_35_50'\n",
    "train.loc[((train['age']>50) & (train['age']<70)), 'age_factor'] = 'b_50_70'\n",
    "train.loc[train['age']>70, 'age_factor'] = 'above_70'\n",
    "\n",
    "test['age_factor'] = 0\n",
    "test.loc[test['age']<10, 'age_factor'] = 'under_10'\n",
    "test.loc[((test['age']>10) & (train['age']<20)), 'age_factor'] = 'b_10_20'\n",
    "test.loc[((test['age']>20) & (train['age']<35)), 'age_factor'] = 'b_20_35'\n",
    "test.loc[((test['age']>35) & (train['age']<50)), 'age_factor'] = 'b_35_50'\n",
    "test.loc[((test['age']>50) & (train['age']<70)), 'age_factor'] = 'b_50_70'\n",
    "test.loc[test['age']>70, 'age_factor'] = 'above_70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['d1_heart_rate_span'] = train['d1_heartrate_max'] - train['d1_heartrate_min']\n",
    "test['d1_heart_rate_span']  = test['d1_heartrate_max'] - test['d1_heartrate_min']\n",
    "\n",
    "train['h1_heart_rate_span'] = train['h1_heartrate_max'] - train['h1_heartrate_min']\n",
    "test['h1_heart_rate_span']  = test['h1_heartrate_max'] - test['h1_heartrate_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbp_risk1(train):\n",
    "\n",
    "    \"\"\"Categorises whether blood pressure is elevated, \n",
    " stage 1 hypertension or stage 2 hypertension\"\"\"\n",
    "    if train['d1_mbp_noninvasive_max'] >= 120 and train['d1_mbp_noninvasive_max'] < 130 and train['d1_mbp_noninvasive_min'] < 80:\n",
    "        bprisk = 'elevated BP'\n",
    "    elif (train['d1_mbp_noninvasive_max'] >= 130 and train['d1_mbp_noninvasive_max'] < 140) or (train['d1_mbp_noninvasive_min'] >= 80 and train['d1_mbp_noninvasive_min']< 90):\n",
    "        bprisk = 'stage 1 hypertension'\n",
    "    elif train['d1_mbp_noninvasive_max'] >= 140 or train['d1_mbp_noninvasive_min'] >= 90:\n",
    "         bprisk = 'stage 2 hypertension'\n",
    "    else:\n",
    "        bprisk = 'NAN'\n",
    "    return bprisk\n",
    "\n",
    "def mbp_risk2(train):\n",
    "\n",
    "    \"\"\"Categorises whether blood pressure is elevated, \n",
    " stage 1 hypertension or stage 2 hypertension\"\"\"\n",
    "    if train['d1_mbp_max'] >= 120 and train['d1_mbp_max'] < 130 and train['d1_mbp_min'] < 80:\n",
    "        bprisk = 'elevated BP'\n",
    "    elif (train['d1_mbp_max'] >= 130 and train['d1_mbp_max'] < 140) or (train['d1_mbp_min'] >= 80 and train['d1_mbp_min']< 90):\n",
    "        bprisk = 'stage 1 hypertension'\n",
    "    elif train['d1_mbp_max'] >= 140 or train['d1_mbp_min'] >= 90:\n",
    "         bprisk = 'stage 2 hypertension'\n",
    "    else:\n",
    "        bprisk = 'NAN'\n",
    "    return bprisk\n",
    "\n",
    "def mbp_risk3(train):\n",
    "\n",
    "    \"\"\"Categorises whether blood pressure is elevated, \n",
    " stage 1 hypertension or stage 2 hypertension\"\"\"\n",
    "    if train['d1_mbp_invasive_max'] >= 120 and train['d1_mbp_invasive_max'] < 130 and train['d1_mbp_invasive_min'] < 80:\n",
    "        bprisk = 'elevated BP'\n",
    "    elif (train['d1_mbp_invasive_max'] >= 130 and train['d1_mbp_invasive_max'] < 140) or (train['d1_mbp_invasive_min'] >= 80 and train['d1_mbp_invasive_min']< 90):\n",
    "        bprisk = 'stage 1 hypertension'\n",
    "    elif train['d1_mbp_invasive_max'] >= 140 or train['d1_mbp_invasive_min'] >= 90:\n",
    "         bprisk = 'stage 2 hypertension'\n",
    "    else:\n",
    "        bprisk = 'NAN'\n",
    "    return bprisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mbp_noninvasive_bp_risk'] = train.apply(mbp_risk1, axis=1)\n",
    "train['mbp_invasive_bp_risk'] = train.apply(mbp_risk3, axis=1)\n",
    "train['mbp_bp_risk'] = train.apply(mbp_risk2, axis=1)\n",
    "\n",
    "test['mbp_noninvasive_bp_risk'] = test.apply(mbp_risk1, axis=1)\n",
    "test['mbp_invasive_bp_risk'] = test.apply(mbp_risk3, axis=1)\n",
    "test['mbp_bp_risk'] = test.apply(mbp_risk2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = 12\n",
    "Y1 =16\n",
    "\n",
    "def resprate_min_resp_classt(num):\n",
    "    if pd.isna(num):\n",
    "        return np.nan\n",
    "    if X1 <= num <= Y1:\n",
    "        return 'normal'\n",
    "    elif num <= 12:\n",
    "        return 'below normal'\n",
    "    elif num >= 16: \n",
    "        return 'above normal'\n",
    "    \n",
    "X2= 12\n",
    "Y2 =16\n",
    "\n",
    "def resprate_max_classt(num):\n",
    "    if pd.isna(num):\n",
    "        return np.nan\n",
    "    if X2 <= num <= Y2:\n",
    "        return 'normal'\n",
    "    elif num <= 12:\n",
    "        return 'below normal'\n",
    "    elif num >= 16: \n",
    "        return 'above normal'\n",
    "    \n",
    "X = 36.5\n",
    "Y =37.5\n",
    "\n",
    "def temp_classt(num):\n",
    "    if pd.isna(num):\n",
    "        return np.nan\n",
    "    if X <= num <= Y:\n",
    "        return 'normal'\n",
    "    elif num <= 36.4:\n",
    "        return 'below normal'\n",
    "    elif num >= 37.6: \n",
    "        return 'above normal'\n",
    "    \n",
    "def weighted_classt(x): \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    elif x < 15: \n",
    "        return 'very severely underweight' \n",
    "    elif x >= 15 and x < 16: \n",
    "        return 'severely weight' \n",
    "    elif x >=16 and x < 18.5: \n",
    "        return 'underweight' \n",
    "    elif x >= 18.5 and x < 25: \n",
    "        return 'healthy weight' \n",
    "    elif x >= 25 and x < 30: \n",
    "        return 'overweight'\n",
    "    elif x >= 30 and x < 35: \n",
    "        return 'class 1' \n",
    "    elif x >= 35 and x < 40: \n",
    "        return 'class 2' \n",
    "    else: \n",
    "        return 'class 3' \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "train['resprate_min'] = train['d1_resprate_min'].map(resprate_min_resp_classt)\n",
    "test['resprate_min'] = test['d1_resprate_min'].map(resprate_min_resp_classt)\n",
    "train['resprate_max'] = train['d1_resprate_max'].map(resprate_max_classt)\n",
    "test['resprate_max'] = test['d1_resprate_max'].map(resprate_max_classt)\n",
    "train['temp_class'] = train['temp_apache'].map(temp_classt)\n",
    "test['temp_class'] = test['temp_apache'].map(temp_classt)\n",
    "train['weightclass'] = train['bmi'].map(weighted_classt)\n",
    "test['weightclass'] = test['bmi'].map(weighted_classt)\n",
    "train['mean_reperate'] = train['d1_resprate_min'] + (train['d1_resprate_min']/2)\n",
    "test['mean_reperate'] = test['d1_resprate_min']+ (test['d1_resprate_min']/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1579794016106,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "uhKO586aSSbs",
    "outputId": "7ce1c594-2b50-4e4d-cf7d-8f3d43712d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91713, 147)\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "#features = ['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob']\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dY4hYR2rs1Dp"
   },
   "outputs": [],
   "source": [
    "############ PARAMETERS\n",
    "\n",
    "# cores\n",
    "cores = 20\n",
    "# cross-validation\n",
    "num_folds = 10\n",
    "shuffle   = True\n",
    "\n",
    "seed = 111\n",
    "\n",
    "# number of trees\n",
    "max_rounds = 10000\n",
    "stopping   = 400\n",
    "verbose    = 250\n",
    "\n",
    "# LGB parameters\n",
    "xgb_params = {\n",
    "    #'booster':          'gbtree',\n",
    "    'objective':         'binary:logistic',\n",
    "    'eval_metric':            'auc',\n",
    "    'alpha':              0.1,\n",
    "    'lambda':             0.1,\n",
    "#    'min_split_gain':    0.1,\n",
    "#    'min_child_weight':  0,\n",
    "#    'min_child_samples': 10,\n",
    "    'silent':            True,\n",
    "    'verbosity':         2,\n",
    "    'learning_rate':     0.01,\n",
    "    'max_depth':         12,\n",
    "#    'num_leaves':        64,\n",
    "#    'scale_pos_weight':  1,\n",
    "    'num_round':      max_rounds,\n",
    "    'nthread' :          cores,\n",
    "    'seed':      seed,\n",
    "    #\"device\" : \"gpu\"\n",
    "}\n",
    "\n",
    "# data partitinoing\n",
    "folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "\n",
    "# SMOTE settings\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#sm = SMOTE(random_state = seed, n_jobs = cores, sampling_strategy = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2u9ywow1s1Dr"
   },
   "outputs": [],
   "source": [
    "\n",
    "############ PLACEHOLDERS\n",
    "\n",
    "# placeholders\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "\n",
    "# predictions\n",
    "preds_test   = np.zeros(test.shape[0])\n",
    "preds_oof    = np.zeros(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 430526,
     "status": "error",
     "timestamp": 1579794901397,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "q44bOYsSs1Ds",
    "outputId": "6e0f98e9-f2bd-4176-db38-b8ea5d0b2653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between the new feature, ethnicity_Kfold_Target_Enc and, hospital_death is -0.028260843510362073.\n",
      "Correlation between the new feature, gender_Kfold_Target_Enc and, hospital_death is -0.029968692951016104.\n",
      "Correlation between the new feature, hospital_admit_source_Kfold_Target_Enc and, hospital_death is 0.0950020361992956.\n",
      "Correlation between the new feature, icu_admit_source_Kfold_Target_Enc and, hospital_death is 0.10744825680871012.\n",
      "Correlation between the new feature, icu_stay_type_Kfold_Target_Enc and, hospital_death is -0.005314139037831214.\n",
      "Correlation between the new feature, apache_3j_bodysystem_Kfold_Target_Enc and, hospital_death is 0.11922149368146844.\n",
      "Correlation between the new feature, apache_2_bodysystem_Kfold_Target_Enc and, hospital_death is 0.10303327468643929.\n",
      "Correlation between the new feature, age_factor_Kfold_Target_Enc and, hospital_death is 0.0980783795512431.\n",
      "Correlation between the new feature, mbp_noninvasive_bp_risk_Kfold_Target_Enc and, hospital_death is 0.03900254316529864.\n",
      "Correlation between the new feature, mbp_invasive_bp_risk_Kfold_Target_Enc and, hospital_death is 0.02094106310232751.\n",
      "Correlation between the new feature, mbp_bp_risk_Kfold_Target_Enc and, hospital_death is 0.04006919107628493.\n",
      "Correlation between the new feature, resprate_min_Kfold_Target_Enc and, hospital_death is 0.06287014537659953.\n",
      "Correlation between the new feature, resprate_max_Kfold_Target_Enc and, hospital_death is -0.0144750617306641.\n",
      "Correlation between the new feature, temp_class_Kfold_Target_Enc and, hospital_death is 0.07653534528588732.\n",
      "Correlation between the new feature, weightclass_Kfold_Target_Enc and, hospital_death is 0.025849415729605082.\n",
      "Data shape: (82541, 162) (9172, 162)\n",
      "[0]\tvalidation_0-auc:0.868349\tvalidation_1-auc:0.86556\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 400 rounds.\n",
      "--------------------------------\n",
      "FOLD 1: AUC = 0.865560\n",
      "--------------------------------\n",
      "\n",
      "Correlation between the new feature, ethnicity_Kfold_Target_Enc and, hospital_death is -0.022346466491846143.\n",
      "Correlation between the new feature, gender_Kfold_Target_Enc and, hospital_death is -0.021696962881925533.\n",
      "Correlation between the new feature, hospital_admit_source_Kfold_Target_Enc and, hospital_death is 0.09380787822349566.\n",
      "Correlation between the new feature, icu_admit_source_Kfold_Target_Enc and, hospital_death is 0.10696636797177592.\n",
      "Correlation between the new feature, icu_stay_type_Kfold_Target_Enc and, hospital_death is 0.0021589212541410635.\n",
      "Correlation between the new feature, apache_3j_bodysystem_Kfold_Target_Enc and, hospital_death is 0.11743995472300024.\n",
      "Correlation between the new feature, apache_2_bodysystem_Kfold_Target_Enc and, hospital_death is 0.10127650747365524.\n",
      "Correlation between the new feature, age_factor_Kfold_Target_Enc and, hospital_death is 0.09697538727435005.\n",
      "Correlation between the new feature, mbp_noninvasive_bp_risk_Kfold_Target_Enc and, hospital_death is 0.03920666220880895.\n",
      "Correlation between the new feature, mbp_invasive_bp_risk_Kfold_Target_Enc and, hospital_death is 0.020683751069555976.\n",
      "Correlation between the new feature, mbp_bp_risk_Kfold_Target_Enc and, hospital_death is 0.04039813700177058.\n",
      "Correlation between the new feature, resprate_min_Kfold_Target_Enc and, hospital_death is 0.06574338801520864.\n",
      "Correlation between the new feature, resprate_max_Kfold_Target_Enc and, hospital_death is -0.008600280843374124.\n",
      "Correlation between the new feature, temp_class_Kfold_Target_Enc and, hospital_death is 0.07923959664476253.\n",
      "Correlation between the new feature, weightclass_Kfold_Target_Enc and, hospital_death is 0.028563035228678337.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-85ae87e7e9c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# label encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mtrn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m#ros = RandomOverSampler(random_state=seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-49eb48d53b00>\u001b[0m in \u001b[0;36mlabel_encoding\u001b[0;34m(df_train, df_valid, df_test)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mdf_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wids/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wids/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         return _encode_numpy(values, uniques, encode,\n\u001b[0m\u001b[1;32m    118\u001b[0m                              check_unknown=check_unknown)\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wids/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_check_unknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 raise ValueError(\"y contains previously unseen labels: %s\"\n",
      "\u001b[0;32m~/.conda/envs/wids/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_check_unknown\u001b[0;34m(values, uniques, return_mask)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wids/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/wids/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ CROSS-VALIDATION LOOP\n",
    "cv_start  = time.time()\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
    "\n",
    "    # data partitioning\n",
    "    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "    test_x       = test[features]\n",
    "    \n",
    "        \n",
    "    # Fill Na\n",
    "    for feature in ['ethnicity', 'gender']:\n",
    "      trn_x[feature]  = trn_x[feature].fillna(trn_x[feature].mode()[0])\n",
    "      val_x[feature]  = val_x[feature].fillna(trn_x[feature].mode()[0])\n",
    "      test_x[feature] = test_x[feature].fillna(trn_x[feature].mode()[0])\n",
    "\n",
    "    for feature in ['hospital_admit_source', 'icu_admit_source', 'icu_stay_type']:#, 'icu_type']:\n",
    "      trn_x[feature]  = trn_x[feature].fillna('missing')\n",
    "      val_x[feature]  = val_x[feature].fillna('missing')\n",
    "      test_x[feature] = test_x[feature].fillna('missing')\n",
    "    \n",
    "    trn_x = pd.concat([trn_x, trn_y], axis=1)\n",
    "    val_x = pd.concat([val_x, val_y], axis=1)\n",
    "    \n",
    "    for feature in trn_x.select_dtypes('object').columns:    \n",
    "        targetc = KFoldTargetEncoderTrain(feature,'hospital_death',n_fold=10)\n",
    "        trn_x = targetc.fit_transform(trn_x)\n",
    "\n",
    "        test_targetc = KFoldTargetEncoderTest(trn_x,\n",
    "                                              feature,\n",
    "                                              f'{feature}_Kfold_Target_Enc')\n",
    "        test_x = test_targetc.fit_transform(test_x)\n",
    "        \n",
    "        val_targetc = KFoldTargetEncoderTest(trn_x,\n",
    "                                              feature,\n",
    "                                              f'{feature}_Kfold_Target_Enc')\n",
    "        val_x = val_targetc.fit_transform(val_x)\n",
    "        \n",
    "        \n",
    "    \n",
    "    trn_y = trn_x['hospital_death']\n",
    "    trn_x = trn_x.drop('hospital_death', axis=1)\n",
    "    \n",
    "    val_y = val_x['hospital_death']\n",
    "    val_x = val_x.drop('hospital_death', axis=1)\n",
    "    \n",
    "    '''for f in trn_x.columns[trn_x.columns.str.contains('_min')]:\n",
    "        feature_mean = train[f].mean()\n",
    "        trn_x[f'{f}_min_deviation'] = trn_x[f] - feature_mean\n",
    "        val_x[f'{f}_min_deviation'] = val_x[f] - feature_mean\n",
    "        test_x[f'{f}_min_deviation'] = test_x[f] - feature_mean\n",
    "        \n",
    "    for f in trn_x.columns[trn_x.columns.str.contains('_max')]:\n",
    "        feature_mean = train[f].mean()\n",
    "        trn_x[f'{f}_max_deviation'] = trn_x[f] - feature_mean\n",
    "        val_x[f'{f}_max_deviation'] = val_x[f] - feature_mean\n",
    "        test_x[f'{f}_max_deviation'] = test_x[f] - feature_mean'''\n",
    "    \n",
    "    #trn_x['apache_4a_hospital_death_prob'] = trn_x['apache_4a_hospital_death_prob'].fillna(trn_x.groupby(['ethnicity','age_factor','gender','aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure', 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis'])['apache_4a_hospital_death_prob'].transform('median'))\n",
    "    #val_x['apache_4a_hospital_death_prob'] = val_x['apache_4a_hospital_death_prob'].fillna(trn_x.groupby(['ethnicity','age_factor','gender','aids', 'cirrhosis', 'diabetes_mellitus','hepatic_failure', 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis'])['apache_4a_hospital_death_prob'].transform('median'))\n",
    "    #test_x['apache_4a_hospital_death_prob']= test_x['apache_4a_hospital_death_prob'].fillna(trn_x.groupby(['ethnicity','age_factor','gender','aids', 'cirrhosis', 'diabetes_mellitus','hepatic_failure', 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis'])['apache_4a_hospital_death_prob'].transform('median'))\n",
    "    \n",
    "    #trn_x['apache_4a_icu_death_prob'].fillna(trn_x['apache_4a_icu_death_prob'].median())\n",
    "    #val_x['apache_4a_icu_death_prob'].fillna(trn_x['apache_4a_icu_death_prob'].median())\n",
    "    #test_x['apache_4a_icu_death_prob'].fillna(trn_x['apache_4a_icu_death_prob'].median())\n",
    "    \n",
    "    \n",
    "    ''' for feature in ['apache_2_bodysystem', 'apache_3j_bodysystem']:\n",
    "      trn_x[feature]  = trn_x[feature].fillna('ffill')\n",
    "      val_x[feature]  = val_x[feature].fillna('ffill')\n",
    "      test_x[feature] = test_x[feature].fillna('ffill')'''\n",
    "\n",
    "    '''for feature in trn_x.select_dtypes('number').columns:\n",
    "      trn_x[feature]  = trn_x[feature].fillna(-999)\n",
    "      val_x[feature]  = val_x[feature].fillna(-999)\n",
    "      test_x[feature] = test_x[feature].fillna(-999)'''\n",
    "\n",
    "    '''for feature in trn_x.select_dtypes('number').columns:\n",
    "      trn_x[feature]  = trn_x[feature].fillna(trn_x.groupby(['ethnicity','age_factor','gender','hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type'])[feature].transform('mean'))\n",
    "      val_x[feature]  = val_x[feature].fillna(trn_x.groupby(['ethnicity','age_factor','gender','hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type'])[feature].transform('mean'))\n",
    "      test_x[feature] = test_x[feature].fillna(trn_x.groupby(['ethnicity','age_factor','gender','hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type'])[feature].transform('mean'))\n",
    "   ''' \n",
    "\n",
    "    for column in trn_x.select_dtypes('object').columns:\n",
    "        trn_x[column] = trn_x[column].fillna('')\n",
    "        val_x[column] = val_x[column].fillna('')\n",
    "        test_x[column] = test_x[column].fillna('')\n",
    "        \n",
    "    '''for feature in ['d1_diasbp_invasive_max', 'd1_diasbp_invasive_min',\n",
    "                   'd1_mbp_invasive_max', 'd1_mbp_invasive_min',\n",
    "                   'd1_sysbp_invasive_max', 'd1_sysbp_invasive_min',\n",
    "                   'd1_inr_max', 'd1_inr_min', 'h1_inr_max', 'h1_inr_min']:\n",
    "      trn_x[feature]  = trn_x[feature].fillna(trn_x[feature].mode()[0])\n",
    "      val_x[feature]  = val_x[feature].fillna(trn_x[feature].mode()[0])\n",
    "      test_x[feature] = test_x[feature].fillna(trn_x[feature].mode()[0])'''\n",
    "    \n",
    "    # label encoding\n",
    "    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test_x)\n",
    "    \n",
    "    #ros = RandomOverSampler(random_state=seed)\n",
    "    #trn_x, trn_y = ros.fit_resample(trn_x, trn_y)\n",
    "    \n",
    "    # augment training data with SMOTE\n",
    "    #trn_x_, trn_y_ = sm.fit_sample(trn_x[numerics], trn_y)\n",
    "    #trn_x = pd.DataFrame(trn_x_, columns = numerics)\n",
    "    #trn_y = pd.Series(trn_y)\n",
    "    #test_x[features_without_nas] = test_x[features_without_nas].fillna(trn_x[features_without_nas].median())\n",
    "    \n",
    "    #for n in [10, 100]:\n",
    "    #   #print(n)\n",
    "    #    clf = KNeighborsClassifier(n)\n",
    "    #    clf.fit(trn_x[features_without_nas], trn_y)\n",
    "    #    trn_x['neighbors_{n}'] = clf.predict(trn_x[features_without_nas])\n",
    "    #    val_x['neighbors_{n}'] = clf.predict(val_x[features_without_nas])\n",
    "    #    test_x['neighbors_{n}'] = clf.predict(test_x[features_without_nas])\n",
    "       \n",
    "    ## add noise to train to reduce overfitting\n",
    "    trn_x += np.random.normal(0, 0.01, trn_x.shape)\n",
    "    \n",
    "    # print data dimensions\n",
    "    print('Data shape:', trn_x.shape, val_x.shape)\n",
    "    #print('Data shape:', trn_y.shape, val_y.shape)    \n",
    "    # train lightGBM\n",
    "    clf = xgb.XGBRFClassifier(**xgb_params) \n",
    "    clf = clf.fit(trn_x, trn_y, \n",
    "                  eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                  eval_metric           = 'auc', \n",
    "                  early_stopping_rounds = stopping,\n",
    "                  verbose               = verbose)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "    # find the best iteration\n",
    "    best_iter = clf.best_iteration\n",
    "\n",
    "    # save predictions\n",
    "    preds_oof[val_idx] = clf.predict_proba(val_x,  ntree_limit = best_iter)[:, 1]\n",
    "    preds_test        += clf.predict_proba(test_x, ntree_limit = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "    # importance\n",
    "    fold_importance_df               = pd.DataFrame()\n",
    "    fold_importance_df['Feature']    = trn_x.columns\n",
    "    fold_importance_df['Importance'] = clf.feature_importances_\n",
    "    fold_importance_df['Fold']       = n_fold + 1\n",
    "    importances                      = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "    \n",
    "    # print performance\n",
    "    print('--------------------------------')\n",
    "    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n",
    "    print('--------------------------------')\n",
    "    print('')\n",
    "        \n",
    "    # clear memory\n",
    "    del trn_x, trn_y, val_x, val_y\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# print overall performance    \n",
    "cv_perf = roc_auc_score(y, preds_oof)\n",
    "print('--------------------------------')\n",
    "print('- OOF AUC = %.6f' % cv_perf)\n",
    "print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWHIEpSds1Du"
   },
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZNWGMc6s1Dv"
   },
   "outputs": [],
   "source": [
    "############ RECHECK PERFORMANCE  \n",
    "\n",
    "# check performance\n",
    "print(np.round(roc_auc_score(y, preds_oof), 5))\n",
    "\n",
    "\n",
    "############ TRACK RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2w6VAeHs1Dw"
   },
   "outputs": [],
   "source": [
    "############ VARIABLE IMPORTANCE\n",
    "\n",
    "# load importance    \n",
    "top_feats = 300\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n",
    "importance = importances.loc[importances.Feature.isin(cols)]\n",
    "    \n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 150))\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n",
    "plt.tight_layout()\n",
    "plt.savefig('./var_importance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UbGUmx1s1Dy"
   },
   "source": [
    "SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1579793483507,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "Ut1uW95ds1Dy",
    "outputId": "e9f224fc-7769-45d9-85a5-92ccead9e441"
   },
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'xgb_v1'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + '_' + perf\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1579793484594,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "ox2RkuQks1D0",
    "outputId": "1c58a4f9-c838-44c5-da4a-01705b9c9b64"
   },
   "outputs": [],
   "source": [
    "# export OOF preds\n",
    "oof = pd.DataFrame({'encounter_id': train['encounter_id'], 'hospital_death': preds_oof})\n",
    "oof.to_csv('../oof_preds/' + str(name) + '.csv', index = False)\n",
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1579793485711,
     "user": {
      "displayName": "Elizaveta",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64",
      "userId": "01253993997636551956"
     },
     "user_tz": -60
    },
    "id": "JprRz1pPs1D1",
    "outputId": "b5516a30-8799-4813-94af-c40870ea0e94"
   },
   "outputs": [],
   "source": [
    "\n",
    "# export submission\n",
    "sub = pd.DataFrame({'encounter_id': test['encounter_id'], 'hospital_death': preds_test})\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_1_lgb_main_COLAB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
