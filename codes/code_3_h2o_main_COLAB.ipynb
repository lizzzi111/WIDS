{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"code_3_h2o_main_COLAB.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"1dBSQdRQnzD7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"outputId":"62ffa78c-5af4-4d67-a957-e6732c64146d","executionInfo":{"status":"ok","timestamp":1579719677566,"user_tz":-60,"elapsed":26229,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}}},"source":["!pip install h2o"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting h2o\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/09/c10dda3ad7633c7d12c04f739de82e181c52b9c4efc5133470a542b6d942/h2o-3.28.0.2.tar.gz (126.2MB)\n","\u001b[K     |████████████████████████████████| 126.2MB 92kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.21.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n","Collecting colorama>=0.3.8\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n","Building wheels for collected packages: h2o\n","  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for h2o: filename=h2o-3.28.0.2-py2.py3-none-any.whl size=126306423 sha256=e0ed8ad935246e745461eed66c91aee0bcdcae91f2b5353ddcb131e0ada87765\n","  Stored in directory: /root/.cache/pip/wheels/aa/ef/05/cc37b576425ec5a47be07cc42aa60c6e8b3fc21119808a6b63\n","Successfully built h2o\n","Installing collected packages: colorama, h2o\n","Successfully installed colorama-0.4.3 h2o-3.28.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TJLXVEldsT0N","colab_type":"code","colab":{}},"source":["import h2o\n","from h2o.automl import H2OAutoML"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CV6Ca0tct9t6","colab_type":"code","colab":{}},"source":["###############################\n","#                             #\n","#        ENCODE FACTORS       #\n","#                             #\n","###############################\n","\n","# performs label encoding\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","def label_encoding(df_train, df_valid, df_test):\n","    \n","    factors = df_train.select_dtypes('object').columns\n","    \n","    lbl = LabelEncoder()\n","\n","    for f in factors:        \n","        lbl.fit(list(df_train[f].values) + list(df_valid[f].values) + list(df_test[f].values))\n","        df_train[f] = lbl.transform(list(df_train[f].values))\n","        df_valid[f] = lbl.transform(list(df_valid[f].values))\n","        df_test[f]  = lbl.transform(list(df_test[f].values))\n","\n","    return df_train, df_valid, df_test\n","\n","from sklearn import base\n","class KFoldTargetEncoderTrain(base.BaseEstimator,\n","                               base.TransformerMixin):\n","    def __init__(self,colnames,targetName,\n","                  n_fold=5, verbosity=True,\n","                  discardOriginal_col=False):\n","        self.colnames = colnames\n","        self.targetName = targetName\n","        self.n_fold = n_fold\n","        self.verbosity = verbosity\n","        self.discardOriginal_col = discardOriginal_col\n","    def fit(self, X, y=None):\n","        return self\n","    def transform(self,X):\n","        assert(type(self.targetName) == str)\n","        assert(type(self.colnames) == str)\n","        assert(self.colnames in X.columns)\n","        assert(self.targetName in X.columns)\n","        mean_of_target = X[self.targetName].mean()\n","        kf = KFold(n_splits = self.n_fold,\n","                   shuffle = False, random_state=2019)\n","        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n","        X[col_mean_name] = np.nan\n","        for tr_ind, val_ind in kf.split(X):\n","            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n","            X.loc[X.index[val_ind], col_mean_name] =  X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n","            X[col_mean_name].fillna(mean_of_target, inplace = True)\n","        if self.verbosity:\n","            encoded_feature = X[col_mean_name].values\n","            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,self.targetName, np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n","        if self.discardOriginal_col:\n","            X = X.drop(self.targetName, axis=1)\n","        return X\n","\n","class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n","    \n","    def __init__(self,train,colNames,encodedName):\n","        \n","        self.train = train\n","        self.colNames = colNames\n","        self.encodedName = encodedName\n","        \n","    def fit(self, X, y=None):\n","        return self\n","    def transform(self,X):\n","        mean =  self.train[[self.colNames,\n","                self.encodedName]].groupby(\n","                                self.colNames).mean().reset_index() \n","        \n","        dd = {}\n","        for index, row in mean.iterrows():\n","            dd[row[self.colNames]] = row[self.encodedName]\n","        X[self.encodedName] = X[self.colNames]\n","        X = X.replace({self.encodedName: dd})\n","        return X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7kiA-DotHK8","colab_type":"code","outputId":"ff26cb30-786f-4ece-ec40-0b94347dbd97","executionInfo":{"status":"ok","timestamp":1579724368058,"user_tz":-60,"elapsed":1370,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# GOOGLE COLAB SETUP\n","\n","# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PoNai-lPtJZe","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('drive/My Drive/Colab Notebooks/WIDS/WIDS/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kraLQ_ACs1DU","colab_type":"code","colab":{}},"source":["\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.style.use('dark_background')\n","%matplotlib inline\n","\n","import os\n","import time\n","import datetime\n","import random\n","import multiprocessing\n","import pickle\n","\n","import scipy.stats\n","\n","import gc\n","gc.enable()\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n","from sklearn.preprocessing import RobustScaler, LabelEncoder\n","from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix\n","\n","import lightgbm as lgb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaAGEJRotC7j","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('drive/My Drive/Colab Notebooks/WIDS/WIDS/codes')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnKQLwT_s1Da","colab_type":"code","colab":{}},"source":["############ RANDOMNESS\n","\n","# seed function\n","def seed_everything(seed = 42):\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    \n","# set seed\n","seed = 42\n","seed_everything(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTrTKS7gs1Db","colab_type":"text"},"source":["### IMPORT"]},{"cell_type":"code","metadata":{"id":"Btmfn4ars1Dc","colab_type":"code","outputId":"39471385-9461-4a81-f04f-e1d7500c0b98","executionInfo":{"status":"ok","timestamp":1579724379901,"user_tz":-60,"elapsed":10509,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["############ DATA IMPORT\n","\n","# id data\n","train = pd.read_csv('./raw/training_v2.csv')\n","test  = pd.read_csv('./raw/unlabeled.csv')\n","\n","\n","# check dimensions\n","print(train.shape)\n","print(test.shape)\n","\n","train = train[-train['hospital_death'].isnull()]"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(91713, 186)\n","(39308, 186)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F1LtthC77b22","colab_type":"code","colab":{}},"source":["train['NAs'] = train.isnull().sum(axis=1)\n","test['NAs']  = test.isnull().sum(axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0iX8GebXLAF","colab_type":"code","colab":{}},"source":["train['hospital_id'] = train['hospital_id'].astype('object')\n","test['hospital_id']  = test['hospital_id'].astype('object')\n","\n","train['icu_id'] = train['icu_id'].astype('object')\n","test['icu_id']  = test['icu_id'].astype('object')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"70hZBqHN6Hv5","colab_type":"code","outputId":"24a07064-524a-43cb-f1fc-a3b4cefaa2fa","executionInfo":{"status":"ok","timestamp":1579724392319,"user_tz":-60,"elapsed":21332,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["for feature in train.select_dtypes('object').columns:    \n","    targetc = KFoldTargetEncoderTrain(feature,'hospital_death',n_fold=10)\n","    train = targetc.fit_transform(train)\n","\n","    test_targetc = KFoldTargetEncoderTest(train,\n","                                          feature,\n","                                          f'{feature}_Kfold_Target_Enc')\n","    test = test_targetc.fit_transform(test)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Correlation between the new feature, hospital_id_Kfold_Target_Enc and, hospital_death is 0.061815698066015896.\n","Correlation between the new feature, ethnicity_Kfold_Target_Enc and, hospital_death is -0.021778031915991588.\n","Correlation between the new feature, gender_Kfold_Target_Enc and, hospital_death is -0.02454474750657809.\n","Correlation between the new feature, hospital_admit_source_Kfold_Target_Enc and, hospital_death is 0.09601692398142708.\n","Correlation between the new feature, icu_admit_source_Kfold_Target_Enc and, hospital_death is 0.10751265094405518.\n","Correlation between the new feature, icu_id_Kfold_Target_Enc and, hospital_death is 0.07331137852646111.\n","Correlation between the new feature, icu_stay_type_Kfold_Target_Enc and, hospital_death is -9.430062769421791e-05.\n","Correlation between the new feature, icu_type_Kfold_Target_Enc and, hospital_death is 0.0382226407880874.\n","Correlation between the new feature, apache_3j_bodysystem_Kfold_Target_Enc and, hospital_death is 0.12291914313182137.\n","Correlation between the new feature, apache_2_bodysystem_Kfold_Target_Enc and, hospital_death is 0.10683882439078868.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R3CRPC3ms1Dj","colab_type":"code","colab":{}},"source":["y     = train['hospital_death']\n","train = train.drop('hospital_death', axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cRltychs1Dm","colab_type":"code","colab":{}},"source":["############ FEAUTERS\n","\n","# drop bad features\n","excluded_feats = ['encounter_id', 'patient_id', 'readmission_status', 'hospital_id', 'icu_id']\n","excluded_feats.extend(list(train.select_dtypes('object').columns))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C42jQtu6_3gn","colab_type":"code","colab":{}},"source":["train['apache_prob_prod'] = train['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']\n","test['apache_prob_prod'] = test['apache_4a_hospital_death_prob'] * train[ 'apache_4a_icu_death_prob']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhKO586aSSbs","colab_type":"code","outputId":"efd54b0b-39f2-4c1f-e5dd-4a5c3772448b","executionInfo":{"status":"ok","timestamp":1579724393290,"user_tz":-60,"elapsed":19732,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["features = [f for f in train.columns if f not in excluded_feats]\n","#features = ['apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob']\n","print(train[features].shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["(91713, 184)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dY4hYR2rs1Dp","colab_type":"code","colab":{}},"source":["############ PARAMETERS\n","\n","# cores\n","cores = -1\n","# cross-validation\n","num_folds = 10\n","shuffle   = True\n","\n","# number of trees\n","max_rounds = 10000\n","stopping   = 200\n","verbose    = 250\n","\n","# LGB parameters\n","lgb_params = {\n","    'boosting_type':     'gbdt',\n","    'objective':         'binary',\n","    'metric':            'auc',\n","    'bagging_fraction':  0.9,\n","    'feature_fraction':  0.9,\n","    'lambda_l1':         0.1,\n","    'lambda_l2':         0.1,\n","    'min_split_gain':    0.1,\n","    'min_child_weight':  0,\n","    'min_child_samples': 10,\n","    'silent':            True,\n","    'verbosity':         -1,\n","    'learning_rate':     0.01,\n","    'max_depth':         5,\n","    'num_leaves':        64,\n","    'scale_pos_weight':  1,\n","    'n_estimators':      max_rounds,\n","    'nthread' :          cores,\n","    'random_state':      seed,\n","    #\"device\" : \"gpu\"\n","}\n","\n","# data partitinoing\n","folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n","#folds = GroupKFold(n_splits = num_folds)\n","#folds = model_selection.TimeSeriesSplit(n_splits = 10)\n","\n","# SMOTE settings\n","#from imblearn.over_sampling import SMOTE\n","#sm = SMOTE(random_state = seed, n_jobs = cores, sampling_strategy = 0.05)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2u9ywow1s1Dr","colab_type":"code","colab":{}},"source":["\n","############ PLACEHOLDERS\n","\n","# placeholders\n","clfs = []\n","importances = pd.DataFrame()\n","\n","# predictions\n","preds_test   = np.zeros(test.shape[0])\n","preds_oof    = np.zeros(train.shape[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eh2F5rOasPvR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":562},"outputId":"d73294dc-6116-4c90-b1fd-509f8927278d","executionInfo":{"status":"ok","timestamp":1579724419494,"user_tz":-60,"elapsed":43741,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}}},"source":["h2o.init()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n","Attempting to start a local H2O server...\n","  Java Version: openjdk version \"11.0.5\" 2019-10-15; OpenJDK Runtime Environment (build 11.0.5+10-post-Ubuntu-0ubuntu1.118.04); OpenJDK 64-Bit Server VM (build 11.0.5+10-post-Ubuntu-0ubuntu1.118.04, mixed mode, sharing)\n","  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n","  Ice root: /tmp/tmp4zo1lbkr\n","  JVM stdout: /tmp/tmp4zo1lbkr/h2o_unknownUser_started_from_python.out\n","  JVM stderr: /tmp/tmp4zo1lbkr/h2o_unknownUser_started_from_python.err\n","  Server is running at http://127.0.0.1:54323\n","Connecting to H2O server at http://127.0.0.1:54323 ... successful.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n","<td>06 secs</td></tr>\n","<tr><td>H2O cluster timezone:</td>\n","<td>Etc/UTC</td></tr>\n","<tr><td>H2O data parsing timezone:</td>\n","<td>UTC</td></tr>\n","<tr><td>H2O cluster version:</td>\n","<td>3.28.0.2</td></tr>\n","<tr><td>H2O cluster version age:</td>\n","<td>2 days </td></tr>\n","<tr><td>H2O cluster name:</td>\n","<td>H2O_from_python_unknownUser_71hfe8</td></tr>\n","<tr><td>H2O cluster total nodes:</td>\n","<td>1</td></tr>\n","<tr><td>H2O cluster free memory:</td>\n","<td>3 Gb</td></tr>\n","<tr><td>H2O cluster total cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O cluster allowed cores:</td>\n","<td>2</td></tr>\n","<tr><td>H2O cluster status:</td>\n","<td>accepting new members, healthy</td></tr>\n","<tr><td>H2O connection url:</td>\n","<td>http://127.0.0.1:54323</td></tr>\n","<tr><td>H2O connection proxy:</td>\n","<td>{'http': None, 'https': None}</td></tr>\n","<tr><td>H2O internal security:</td>\n","<td>False</td></tr>\n","<tr><td>H2O API Extensions:</td>\n","<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n","<tr><td>Python version:</td>\n","<td>3.6.9 final</td></tr></table></div>"],"text/plain":["--------------------------  ------------------------------------------------------------------\n","H2O cluster uptime:         06 secs\n","H2O cluster timezone:       Etc/UTC\n","H2O data parsing timezone:  UTC\n","H2O cluster version:        3.28.0.2\n","H2O cluster version age:    2 days\n","H2O cluster name:           H2O_from_python_unknownUser_71hfe8\n","H2O cluster total nodes:    1\n","H2O cluster free memory:    3 Gb\n","H2O cluster total cores:    2\n","H2O cluster allowed cores:  2\n","H2O cluster status:         accepting new members, healthy\n","H2O connection url:         http://127.0.0.1:54323\n","H2O connection proxy:       {'http': None, 'https': None}\n","H2O internal security:      False\n","H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n","Python version:             3.6.9 final\n","--------------------------  ------------------------------------------------------------------"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"q44bOYsSs1Ds","colab_type":"code","outputId":"9abe752c-7657-4a5e-bc49-db97d0ffbb43","executionInfo":{"status":"ok","timestamp":1579711575456,"user_tz":-60,"elapsed":1116733,"user":{"displayName":"Elizaveta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCeI0QdxlRLcqMztd5HySSXx9D_ct4tg31n5g9W=s64","userId":"01253993997636551956"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["############ CROSS-VALIDATION LOOP\n","cv_start  = time.time()\n","for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n","\n","    # data partitioning\n","    trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n","    val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n","    test_x       = test[features]\n","        \n","    # Fill Na\n","    #trn_x['weight']  = trn_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n","    #val_x['weight']  = val_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n","    #test_x['weight'] = test_x['weight'].fillna(trn_x.groupby(['ethnicity','age','gender'])['weight'].transform('mean'))\n","    \n","    #trn_x['height']  = trn_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n","    #val_x['height']  = val_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n","    #test_x['height'] = test_x['height'].fillna(trn_x.groupby(['ethnicity','age','gender'])['height'].transform('mean'))\n","    \n","    #trn_x['bmi']  = trn_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n","    #val_x['bmi']  = val_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n","    #test_x['bmi'] = test_x['bmi'].fillna(trn_x.groupby(['ethnicity','age','gender'])['bmi'].transform('mean'))\n","    \n","    for column in trn_x.select_dtypes('object').columns:\n","        trn_x[column] = trn_x[column].fillna('')\n","        val_x[column] = val_x[column].fillna('')\n","        test_x[column] = test_x[column].fillna('')\n","        \n","    # label encoding\n","    trn_x, val_x, test_x = label_encoding(trn_x, val_x, test_x)\n","       \n","    ## add noise to train to reduce overfitting\n","    trn_x += np.random.normal(0, 0.01, trn_x.shape)\n","    \n","    x_ = list(trn_x.columns)\n","    y_ = 'hospital_death'\n","\n","    trn_x = h2o.H2OFrame(pd.concat([trn_y, trn_x], axis=1))\n","    val_x = h2o.H2OFrame(pd.concat([val_y, val_x], axis=1))\n","    if n_fold == 0:\n","      test_x = h2o.H2OFrame(test_x)\n","\n","    trn_x['hospital_death'] = trn_x['hospital_death'].asfactor()\n","    val_x['hospital_death'] = val_x['hospital_death'].asfactor()\n","\n","    # print data dimensions\n","    print('Data shape:', trn_x.shape, val_x.shape)\n","    #print('Data shape:', trn_y.shape, val_y.shape)    \n","    # train lightGBM\n","    aml = H2OAutoML(max_models = 1, seed = seed, stopping_metric = 'auc')\n","    aml.train(x = x_, y = y_, training_frame = trn_x)\n","    \n","\n","    # save predictions\n","    preds_oof[val_idx] = aml.leader.predict(val_x)\n","    preds_test        += aml.leader.predict(test_x) / folds.n_splits \n","\n","    \n","    # print performance\n","    print('--------------------------------')\n","    print('FOLD%2d: AUC = %.6f' % (n_fold + 1, roc_auc_score(y[val_idx], preds_oof[val_idx])))\n","    print('--------------------------------')\n","    print('')\n","        \n","    # clear memory\n","    del trn_x, trn_y, val_x, val_y\n","    gc.collect()\n","    \n","    \n","# print overall performance    \n","cv_perf = roc_auc_score(y, preds_oof)\n","print('--------------------------------')\n","print('- OOF AUC = %.6f' % cv_perf)\n","print('- CV TIME = {:.2f} min'.format((time.time() - cv_start) / 60))\n","print('--------------------------------')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Parse progress: |█████████████████████████████████████████████████████████| 100%\n","Parse progress: |█████████████████████████████████████████████████████████| 100%\n","Parse progress: |█████████████████████████████████████████████████████████| 100%\n","Data shape: (82541, 185) (9172, 185)\n","AutoML progress: |██"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hWHIEpSds1Du","colab_type":"text"},"source":["### EVALUATION"]},{"cell_type":"code","metadata":{"id":"lZNWGMc6s1Dv","colab_type":"code","colab":{}},"source":["############ RECHECK PERFORMANCE  \n","\n","# check performance\n","print(np.round(roc_auc_score(y, preds_oof), 5))\n","\n","\n","############ TRACK RESULTS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F2w6VAeHs1Dw","colab_type":"code","colab":{}},"source":["############ VARIABLE IMPORTANCE\n","\n","# load importance    \n","top_feats = 300\n","cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False)[0:top_feats].index\n","importance = importances.loc[importances.Feature.isin(cols)]\n","    \n","# plot variable importance\n","plt.figure(figsize = (10, 150))\n","sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False))\n","plt.tight_layout()\n","plt.savefig('./var_importance.pdf')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UbGUmx1s1Dy","colab_type":"text"},"source":["SUBMISSION"]},{"cell_type":"code","metadata":{"id":"Ut1uW95ds1Dy","colab_type":"code","colab":{}},"source":["# file name\n","model = 'h2o_v1'\n","perf  = str(round(cv_perf, 6))[2:7]\n","name  = model + '_' + perf\n","name"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ox2RkuQks1D0","colab_type":"code","colab":{}},"source":["# export OOF preds\n","oof = pd.DataFrame({'encounter_id': train['encounter_id'], 'hospital_death': preds_oof})\n","oof.to_csv('./oof_preds/' + str(name) + '.csv', index = False)\n","oof.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JprRz1pPs1D1","colab_type":"code","colab":{}},"source":["\n","# export submission\n","sub = pd.DataFrame({'encounter_id': test['encounter_id'], 'hospital_death': preds_test})\n","sub.to_csv('./submissions/' + str(name) + '.csv', index = False)\n","sub.head()"],"execution_count":0,"outputs":[]}]}